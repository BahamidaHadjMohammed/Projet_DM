{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "class DBSCANScratch:\n",
    "    def __init__(self, eps, min_samples):\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = X.astype(np.float32)\n",
    "        n = X.shape[0]\n",
    "        tree = KDTree(X)\n",
    "        labels = -np.ones(n, dtype=int)\n",
    "        visited = np.zeros(n, dtype=bool)\n",
    "        cluster_id = 0\n",
    "\n",
    "        for i in range(n):\n",
    "            if visited[i]:\n",
    "                continue\n",
    "\n",
    "            visited[i] = True\n",
    "            neighbors = tree.query_ball_point(X[i], self.eps)\n",
    "\n",
    "            if len(neighbors) < self.min_samples:\n",
    "                labels[i] = -1\n",
    "            else:\n",
    "                self._expand_cluster(i, neighbors, labels, visited, tree, cluster_id, X)\n",
    "                cluster_id += 1\n",
    "\n",
    "        self.labels_ = labels\n",
    "        return self\n",
    "\n",
    "    def _expand_cluster(self, point, neighbors, labels, visited, tree, cluster_id, X):\n",
    "        labels[point] = cluster_id\n",
    "        i = 0\n",
    "        while i < len(neighbors):\n",
    "            p = neighbors[i]\n",
    "            if not visited[p]:\n",
    "                visited[p] = True\n",
    "                new_neighbors = tree.query_ball_point(X[p], self.eps)\n",
    "                if len(new_neighbors) >= self.min_samples:\n",
    "                    neighbors += new_neighbors\n",
    "            if labels[p] == -1:\n",
    "                labels[p] = cluster_id\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_engineered = pd.read_csv(\"/content/content/fire_data_engineered.csv\")\n",
    "\n",
    "non_numeric_cols = df_engineered.select_dtypes(\n",
    "    include=['object', 'category']\n",
    ").columns\n",
    "\n",
    "print(\"Non-numeric columns still present:\")\n",
    "print(non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Select numeric columns FIRST (while still a DataFrame)\n",
    "exclude_cols = ['class']\n",
    "X_df = df_engineered.drop(columns=exclude_cols, errors='ignore')\n",
    "X_df = X_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# 2. Replace inf / -inf with NaN\n",
    "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 3. Handle NaNs (choose ONE strategy)\n",
    "\n",
    "# Option A (recommended for DBSCAN): drop rows\n",
    "X_df = X_df.dropna()\n",
    "\n",
    "# Option B: fill with median (only if dropping hurts too much)\n",
    "# X_df = X_df.fillna(X_df.median())\n",
    "\n",
    "# 4. Convert to NumPy\n",
    "X = X_df.to_numpy()\n",
    "\n",
    "# 5. Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 6. Cast AFTER scaling (important)\n",
    "X_scaled = X_scaled.astype(np.float32)\n",
    "\n",
    "# 7. Sanity checks\n",
    "print(\"Final DBSCAN input shape:\", X_scaled.shape)\n",
    "print(\"Any NaNs:\", np.isnan(X_scaled).any())\n",
    "print(\"Any infs:\", np.isinf(X_scaled).any())\n",
    "print(\"Max abs value:\", np.max(np.abs(X_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfdd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_scratch = DBSCANScratch(eps=0.5, min_samples=5)\n",
    "dbscan_scratch.fit(X_scaled)\n",
    "labels_scratch = dbscan_scratch.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan_sklearn = DBSCAN(\n",
    "    eps=0.5,\n",
    "    min_samples=5,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "labels_sklearn = dbscan_sklearn.fit_predict(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da656ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(labels, name):\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = np.sum(labels == -1)\n",
    "    print(f\"{name}\")\n",
    "    print(\"Clusters:\", n_clusters)\n",
    "    print(\"Noise points:\", n_noise)\n",
    "    print()\n",
    "\n",
    "summarize(labels_scratch, \"Scratch DBSCAN\")\n",
    "summarize(labels_sklearn, \"Sklearn DBSCAN\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
